---
title: "Ensembles - Stacking"
author: "Miguel Conde"
date: "22 de febrero de 2017"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      fig.align = "center")
```

Antes de empezar,cargamos los datos y los preparamos:

```{r}
library(C50)
data(churn)

churn <- rbind(churnTrain, churnTest)

# Variables target y predictoras (features)
target      <- "churn"
predictoras <- names(churn)[names(churn) != target]

# Convertimos factors a integer para que no nos de problemas con svm ni xgbm
for (v in predictoras) {
  if (is.factor(churn[, v])) {
    newName <- paste0("F_", v)
    names(churn)[which(names(churn) == v)] <- newName
    churn[, v] <-  unclass(churn[, newName])
  }
}

churnTrain <- churn[1:nrow(churnTrain), ]
churnTest  <- churn[(nrow(churnTrain) + 1):nrow(churn), ]

rm(churn)

library(caret)
set.seed(123)
```


## Modelos de segundo nivel: red neuronal, random forest, extreme gradient boosting y support vector machine
Vamos a seleccionar ahora un modelo de segundo nivel un poco más complejo entre varios posibles: una red neuronal, un random forest, un extreme gradient boosting y un support vector machine.

Ahora puedo utilizar `caret` para construir tanto los modelos de primer nivel como los de segundo. Por tanto, puedo validarlos mediante la técnica *cross validation* que puedo utilizar a partir del *train set*, sin necesidad de utiliizar un *validation set* aparte para ello.

Construyamos los modelos de primer nivel:
```{r}
churn_train <- churnTrain
churn_test  <- churnTest

trControl <- trainControl(
                          # 5-fold Cross Validation
                          method = "cv", 
                          number = 5,
                          # Save the predictions for the optimal tuning 
                          # parameters
                          savePredictions = 'final', 
                          # Class probabilities will be computed along with
                          # predicted values in each resample
                          classProbs = TRUE
                         ) 

model_rf   <- train(churn_train[ , predictoras], churn_train[ , target],
                    method     = "rf",
                    trControl  = trControl,
                    tuneLength = 3)
model_svm  <- train(churn_train[ , predictoras], churn_train[ , target],
                    method     = "svmRadial",
                    trControl  = trControl,
                    tuneLength = 3)
model_xgbm <- train(churn_train[ , predictoras], churn_train[ , target],
                    method     = "xgbTree",
                    trControl  = trControl,
                    tuneLength = 3)
```

Ahora compararíamos la *performance* y la correlación de los modelos de primer nivel como hemos hecho antes, por eso no vamos a repetirlo.

Pasamos, pues, directamente, a construir los modelos de segundo nivel, en este caso a partir del *train_set*:
```{r}
# Utilizamos los modelos de 1er nivel para predecir las probabilidades 
# Out-Of-Fold del training set
churn_train$OOF_pred_rf <- 
  model_rf$pred$yes[order(model_rf$pred$rowIndex)]
churn_train$OOF_pred_svm <- 
  model_svm$pred$yes[order(model_svm$pred$rowIndex)]
churn_train$OOF_pred_xgbm <-
  model_xgbm$pred$yes[order(model_xgbm$pred$rowIndex)]

```

Hay que hacer notar que siempre debemos emplear en esta fase las predicciones *out of bag* o *out of fold*; de otra manera la importancia de los modelos de primer nivel sería tan solo función de lo bien que cada modelo de primer nivel es capaz de "recordar" los datos de entrenamiento.

Ahora ya podemos entrenar los modelos de segundo nivel:
```{r}
# Predictoras de los modelos de primer nivel para el segundo nivel
predictoras2N <- c('OOF_pred_rf','OOF_pred_svm','OOF_pred_xgbm') 

trControl <- trainControl(
                          # 5-fold Cross Validation
                          method = "cv", 
                          number = 5,
                          # Class probabilities will be computed along with
                          # predicted values in each resample
                          classProbs = TRUE
                         ) 

model_2nn   <- train(churn_train[ , predictoras2N], churn_train[ , target],
                     method     = "nnet",
                     # Neural nets like scaled and normalized inputs
                     preProcess = c("center", "scale"),
                     trace      = FALSE,
                     trControl  = trControl,
                     tuneLength = 3)
model_2rf   <- train(churn_train[ , predictoras2N], churn_train[ , target],
                     method     = "rf",
                     trControl  = trControl,
                     tuneLength = 3)
model_2svm  <- train(churn_train[ , predictoras2N], churn_train[ , target],
                     method     = "svmRadial",
                     trControl  = trControl,
                     tuneLength = 3)
model_2xgbm <- train(churn_train[ , predictoras2N], churn_train[ , target],
                     method     = "xgbTree",
                     trControl  = trControl,
                     tuneLength = 3)
```

Y compararlos:
```{r}
resamps <- resamples(list(nnet = model_2nn, rf = model_2rf, 
                          svm = model_2svm, xgbm = model_2xgbm))
summary(resamps)
```

```{r}
bwplot(resamps)
```

```{r}
diffs <- diff(resamps)
summary(diffs)
```

`xgbm` y random forest son virtualmente indistinguibles.

Como `xgbm` es ligeramente superior en *accuracy* y en *Kappa* a `nnet`, nos quedaremos con `xgbm` como modelo final.

Solo nos queda ya comprobar el resultado con el *test set*:

```{r}
churn_test$OOF_pred_rf   <- predict(model_rf, churn_test[, predictoras],
                                    type = "prob")$yes
churn_test$OOF_pred_svm  <- predict(model_svm, churn_test[, predictoras],
                                    type = "prob")$yes
churn_test$OOF_pred_xgbm <- predict(model_xgbm, churn_test[, predictoras],
                                    type = "prob")$yes

churn_test$pred_nn <- predict(model_2xgbm, churn_test[, predictoras2N])
```

```{r}
confusionMatrix(churn_test$churn, churn_test$pred_nn)
```

